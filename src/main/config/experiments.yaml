defaults:
  - benchmark: simple_benchmark_lean
  - run_settings: default_data_generation_transforms
  - env_settings: bm25_retrieval
  - override hydra/job_logging: 'disabled'

# To run this experiment, execute the following command:

# Few shot Lean
# nohup python src/main/eval_benchmark.py prompt_settings=lean_few_shot env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_lean  &

# Dfs Agent Lean
# nohup python src/main/eval_benchmark.py prompt_settings=lean_dfs env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt4_always_retrieve_no_ex benchmark=simple_benchmark_lean  &

# Few shot Coq
# nohup python src/main/eval_benchmark.py prompt_settings=coq_few_shot env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_1  &

# Dfs Agent Coq
# nohup python src/main/eval_benchmark.py prompt_settings=coq_dfs_always_retrieve env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt4_always_retrieve_no_ex benchmark=simple_benchmark_1  &